{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmamur/elementsem/blob/main/elembert_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a7b1fb1b",
      "metadata": {
        "id": "a7b1fb1b",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import pickle,random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Embedding,Dense,Dropout,Input,Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow.keras.backend as K\n",
        "import re, glob,os,sys\n",
        "from collections import defaultdict\n",
        "from tensorflow.python.keras.utils.vis_utils import plot_model\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/dmamur/elementsem.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgmyMBD2uJtw",
        "outputId": "d09d1632-0a8f-4284-d27a-f471df5d296b"
      },
      "id": "zgmyMBD2uJtw",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'elementsem'...\n",
            "remote: Enumerating objects: 331, done.\u001b[K\n",
            "remote: Counting objects: 100% (49/49), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 331 (delta 19), reused 0 (delta 0), pack-reused 282\u001b[K\n",
            "Receiving objects: 100% (331/331), 74.41 MiB | 10.50 MiB/s, done.\n",
            "Resolving deltas: 100% (132/132), done.\n",
            "Updating files: 100% (236/236), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "2c15c928",
      "metadata": {
        "id": "2c15c928"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "    MAX_LEN = 128\n",
        "    BATCH_SIZE = 32\n",
        "    LR = 0.001\n",
        "    VOCAB_SIZE = 128\n",
        "    EMBED_DIM = 32\n",
        "    NUM_HEAD = 2 # used in bert model\n",
        "    FF_DIM = 2 # used in bert model\n",
        "    NUM_LAYERS = 2\n",
        "    MNAME = 'elembert_'\n",
        "    MVER = 'V1'\n",
        "    DSPATH=\"/content/elementsem/data/\"\n",
        "    PREPATH=\"/content/elementsem/models/pretrained/\"\n",
        "    PATH=\"/content/elementsem/models/\"\n",
        "config = Config()\n",
        "seed=123456789\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds = 'toxic_sr-atad5'\n",
        "mname=config.PATH+config.MNAME+ds+'_%s_E_%s_H_%s_L_%s' % (config.MVER,config.EMBED_DIM,config.NUM_HEAD,config.NUM_LAYERS)"
      ],
      "metadata": {
        "id": "_jqCYhXXJxjE"
      },
      "id": "_jqCYhXXJxjE",
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "86baf7df",
      "metadata": {
        "id": "86baf7df"
      },
      "source": [
        "# Load vocabulary and types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "5fa12f0c",
      "metadata": {
        "id": "5fa12f0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91ddb0fd-014b-4fcf-ebda-de303dc3fc8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocabSize:  565\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(config.DSPATH+ds+'_ds.csv')\n",
        "\n",
        "types = df['types'+config.MVER].apply(eval).apply(list)\n",
        "labels  = to_categorical(np.asarray(df['labels']))\n",
        "uniquelbls=len(np.unique(np.asarray(df['labels'])))\n",
        "\n",
        "with open(config.PREPATH+'/el2id'+config.MVER+'.pkl', 'rb') as f:\n",
        "    db = pickle.load(f)\n",
        "\n",
        "element2id = db['el2id']\n",
        "el2id = db['el2id']\n",
        "config.VOCAB_SIZE = len(element2id)\n",
        "print('vocabSize: ', config.VOCAB_SIZE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert types to integers"
      ],
      "metadata": {
        "id": "x52k2FYzNWS8"
      },
      "id": "x52k2FYzNWS8"
    },
    {
      "cell_type": "code",
      "source": [
        "types0=[['[CLS]']+i+['[SEP]'] for i in types]\n",
        "typesNumerical=[]\n",
        "for i in types0:\n",
        "    typesNumerical.append([element2id[j] for j in i])\n",
        "\n",
        "x3 = tf.keras.preprocessing.sequence.pad_sequences(typesNumerical,dtype='int32',padding= 'post',truncating='post',maxlen=config.MAX_LEN)\n",
        "\n",
        "#z = load_model(config.PREPATH+'/elembert_'+config.MVER+'_E_'+config.EMBED_DIM.+'_H_'+config.NUM_HEAD+'_L_'+config.NUM_LAYERS+'_bert.h5',compile=False)\n",
        "z = load_model(config.PREPATH+'/elembert_%s_E_%s_H_%s_L_%s_bert.h5' % (config.MVER,config.EMBED_DIM,config.NUM_HEAD,config.NUM_LAYERS),compile=False)\n",
        "z.trainable = True\n",
        "\n",
        "e = Lambda(lambda x: x[:,0],name='clsTokenEmb')(z.output)\n",
        "f = Dense(uniquelbls, activation=\"softmax\",name='out_tox')(e)\n",
        "\n",
        "model = Model(inputs=z.input, outputs=f)\n",
        "\n",
        "#plot_model(model, show_shapes=True, show_layer_names=True,to_file=mname+\".png\")\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=config.LR)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[tf.keras.metrics.AUC()])\n",
        "\n",
        "epochs=2*config.BATCH_SIZE\n",
        "model.summary()\n",
        "\n",
        "csv_logger = tf.keras.callbacks.CSVLogger(mname+\"_log.csv\", append=True)\n",
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(mname+\".h5\",verbose=2, mode='min',save_freq=1000,)\n",
        "\n",
        "callbacks_list = [checkpoint,csv_logger]\n",
        "\n",
        "print('dataLen: ',x3.shape,labels.shape)\n",
        "\n",
        "p = np.random.RandomState(seed=seed).permutation(len(labels))\n",
        "n = len(p)\n",
        "\n",
        "trainidx=p[:round(len(p)*0.8)]\n",
        "validx = p[int(n*0.8):int(n*0.9)]\n",
        "testidx = p[int(n*0.9):]\n",
        "\n",
        "trainlog = model.fit(x=x3[trainidx], y=labels[trainidx],\n",
        "                     validation_data = (x3[validx],labels[validx]),\n",
        "                     verbose = 1,epochs = epochs, batch_size = config.BATCH_SIZE,callbacks = callbacks_list)\n",
        "\n",
        "model.save(mname+\".h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZPse7PrNU1v",
        "outputId": "d928e892-77bc-48ac-ce26-a0c4d6164016"
      },
      "id": "oZPse7PrNU1v",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_16\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " types (InputLayer)             [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " element_embdgs (Embedding)     (None, 128, 32)      18080       ['types[0][0]']                  \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  (None, 128, 32)     0           ['element_embdgs[0][0]']         \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " encoder_0/multiheadattention (  (None, 128, 32)     4224        ['tf.__operators__.add[0][0]',   \n",
            " MultiHeadAttention)                                              'tf.__operators__.add[0][0]',   \n",
            "                                                                  'tf.__operators__.add[0][0]']   \n",
            "                                                                                                  \n",
            " encoder_0/att_dropout (Dropout  (None, 128, 32)     0           ['encoder_0/multiheadattention[0]\n",
            " )                                                               [0]']                            \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TFOpLa  (None, 128, 32)     0           ['tf.__operators__.add[0][0]',   \n",
            " mbda)                                                            'encoder_0/att_dropout[0][0]']  \n",
            "                                                                                                  \n",
            " encoder_0/att_layernormalizati  (None, 128, 32)     64          ['tf.__operators__.add_1[0][0]'] \n",
            " on (LayerNormalization)                                                                          \n",
            "                                                                                                  \n",
            " encoder_0/ffn (Sequential)     (None, 128, 32)      2112        ['encoder_0/att_layernormalizatio\n",
            "                                                                 n[0][0]']                        \n",
            "                                                                                                  \n",
            " encoder_0/ffn_dropout (Dropout  (None, 128, 32)     0           ['encoder_0/ffn[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.__operators__.add_2 (TFOpLa  (None, 128, 32)     0           ['encoder_0/att_layernormalizatio\n",
            " mbda)                                                           n[0][0]',                        \n",
            "                                                                  'encoder_0/ffn_dropout[0][0]']  \n",
            "                                                                                                  \n",
            " encoder_0/ffn_layernormalizati  (None, 128, 32)     64          ['tf.__operators__.add_2[0][0]'] \n",
            " on (LayerNormalization)                                                                          \n",
            "                                                                                                  \n",
            " encoder_1/multiheadattention (  (None, 128, 32)     4224        ['encoder_0/ffn_layernormalizatio\n",
            " MultiHeadAttention)                                             n[0][0]',                        \n",
            "                                                                  'encoder_0/ffn_layernormalizatio\n",
            "                                                                 n[0][0]',                        \n",
            "                                                                  'encoder_0/ffn_layernormalizatio\n",
            "                                                                 n[0][0]']                        \n",
            "                                                                                                  \n",
            " encoder_1/att_dropout (Dropout  (None, 128, 32)     0           ['encoder_1/multiheadattention[0]\n",
            " )                                                               [0]']                            \n",
            "                                                                                                  \n",
            " tf.__operators__.add_3 (TFOpLa  (None, 128, 32)     0           ['encoder_0/ffn_layernormalizatio\n",
            " mbda)                                                           n[0][0]',                        \n",
            "                                                                  'encoder_1/att_dropout[0][0]']  \n",
            "                                                                                                  \n",
            " encoder_1/att_layernormalizati  (None, 128, 32)     64          ['tf.__operators__.add_3[0][0]'] \n",
            " on (LayerNormalization)                                                                          \n",
            "                                                                                                  \n",
            " encoder_1/ffn (Sequential)     (None, 128, 32)      2112        ['encoder_1/att_layernormalizatio\n",
            "                                                                 n[0][0]']                        \n",
            "                                                                                                  \n",
            " encoder_1/ffn_dropout (Dropout  (None, 128, 32)     0           ['encoder_1/ffn[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.__operators__.add_4 (TFOpLa  (None, 128, 32)     0           ['encoder_1/att_layernormalizatio\n",
            " mbda)                                                           n[0][0]',                        \n",
            "                                                                  'encoder_1/ffn_dropout[0][0]']  \n",
            "                                                                                                  \n",
            " encoder_1/ffn_layernormalizati  (None, 128, 32)     64          ['tf.__operators__.add_4[0][0]'] \n",
            " on (LayerNormalization)                                                                          \n",
            "                                                                                                  \n",
            " clsTokenEmb (Lambda)           (None, 32)           0           ['encoder_1/ffn_layernormalizatio\n",
            "                                                                 n[0][0]']                        \n",
            "                                                                                                  \n",
            " out_tox (Dense)                (None, 2)            66          ['clsTokenEmb[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31,074\n",
            "Trainable params: 31,074\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "dataLen:  (9091, 128) (9091, 2)\n",
            "Epoch 1/64\n",
            "228/228 [==============================] - 13s 28ms/step - loss: 0.2113 - auc_14: 0.9631 - val_loss: 0.1363 - val_auc_14: 0.9756\n",
            "Epoch 2/64\n",
            "228/228 [==============================] - 3s 14ms/step - loss: 0.1538 - auc_14: 0.9747 - val_loss: 0.1358 - val_auc_14: 0.9802\n",
            "Epoch 3/64\n",
            "228/228 [==============================] - 3s 13ms/step - loss: 0.1473 - auc_14: 0.9789 - val_loss: 0.1346 - val_auc_14: 0.9789\n",
            "Epoch 4/64\n",
            "228/228 [==============================] - 4s 16ms/step - loss: 0.1457 - auc_14: 0.9799 - val_loss: 0.1351 - val_auc_14: 0.9822\n",
            "Epoch 5/64\n",
            " 84/228 [==========>...................] - ETA: 1s - loss: 0.1287 - auc_14: 0.9846\n",
            "Epoch 5: saving model to /content/elementsem/models/elembert_toxic_sr-atad5_V1_E_32_H_2_L_2.h5\n",
            "228/228 [==============================] - 3s 13ms/step - loss: 0.1419 - auc_14: 0.9814 - val_loss: 0.1311 - val_auc_14: 0.9806\n",
            "Epoch 6/64\n",
            "228/228 [==============================] - 3s 12ms/step - loss: 0.1392 - auc_14: 0.9829 - val_loss: 0.1318 - val_auc_14: 0.9845\n",
            "Epoch 7/64\n",
            "228/228 [==============================] - 3s 12ms/step - loss: 0.1338 - auc_14: 0.9849 - val_loss: 0.1443 - val_auc_14: 0.9832\n",
            "Epoch 8/64\n",
            "228/228 [==============================] - 4s 15ms/step - loss: 0.1348 - auc_14: 0.9844 - val_loss: 0.1316 - val_auc_14: 0.9829\n",
            "Epoch 9/64\n",
            "175/228 [======================>.......] - ETA: 0s - loss: 0.1298 - auc_14: 0.9856\n",
            "Epoch 9: saving model to /content/elementsem/models/elembert_toxic_sr-atad5_V1_E_32_H_2_L_2.h5\n",
            "228/228 [==============================] - 3s 13ms/step - loss: 0.1321 - auc_14: 0.9851 - val_loss: 0.1269 - val_auc_14: 0.9849\n",
            "Epoch 10/64\n",
            "228/228 [==============================] - 3s 12ms/step - loss: 0.1299 - auc_14: 0.9856 - val_loss: 0.1265 - val_auc_14: 0.9830\n",
            "Epoch 11/64\n",
            "228/228 [==============================] - 3s 12ms/step - loss: 0.1280 - auc_14: 0.9862 - val_loss: 0.1320 - val_auc_14: 0.9832\n",
            "Epoch 12/64\n",
            "228/228 [==============================] - 4s 16ms/step - loss: 0.1278 - auc_14: 0.9860 - val_loss: 0.1273 - val_auc_14: 0.9817\n",
            "Epoch 13/64\n",
            "228/228 [==============================] - 3s 13ms/step - loss: 0.1233 - auc_14: 0.9869 - val_loss: 0.1341 - val_auc_14: 0.9809\n",
            "Epoch 14/64\n",
            " 35/228 [===>..........................] - ETA: 2s - loss: 0.1249 - auc_14: 0.9871\n",
            "Epoch 14: saving model to /content/elementsem/models/elembert_toxic_sr-atad5_V1_E_32_H_2_L_2.h5\n",
            "228/228 [==============================] - 3s 13ms/step - loss: 0.1206 - auc_14: 0.9873 - val_loss: 0.1336 - val_auc_14: 0.9805\n",
            "Epoch 15/64\n",
            "228/228 [==============================] - 3s 13ms/step - loss: 0.1168 - auc_14: 0.9895 - val_loss: 0.1539 - val_auc_14: 0.9801\n",
            "Epoch 16/64\n",
            "228/228 [==============================] - 4s 16ms/step - loss: 0.1149 - auc_14: 0.9895 - val_loss: 0.1409 - val_auc_14: 0.9794\n",
            "Epoch 17/64\n",
            "228/228 [==============================] - 3s 13ms/step - loss: 0.1138 - auc_14: 0.9899 - val_loss: 0.1351 - val_auc_14: 0.9816\n",
            "Epoch 18/64\n",
            "119/228 [==============>...............] - ETA: 1s - loss: 0.1104 - auc_14: 0.9897\n",
            "Epoch 18: saving model to /content/elementsem/models/elembert_toxic_sr-atad5_V1_E_32_H_2_L_2.h5\n",
            "228/228 [==============================] - 4s 17ms/step - loss: 0.1103 - auc_14: 0.9902 - val_loss: 0.1653 - val_auc_14: 0.9768\n",
            "Epoch 19/64\n",
            "228/228 [==============================] - 4s 17ms/step - loss: 0.1059 - auc_14: 0.9913 - val_loss: 0.1381 - val_auc_14: 0.9801\n",
            "Epoch 20/64\n",
            "228/228 [==============================] - 3s 13ms/step - loss: 0.1090 - auc_14: 0.9908 - val_loss: 0.1539 - val_auc_14: 0.9799\n",
            "Epoch 21/64\n",
            "228/228 [==============================] - 3s 13ms/step - loss: 0.1031 - auc_14: 0.9918 - val_loss: 0.1466 - val_auc_14: 0.9786\n",
            "Epoch 22/64\n",
            "207/228 [==========================>...] - ETA: 0s - loss: 0.1022 - auc_14: 0.9917\n",
            "Epoch 22: saving model to /content/elementsem/models/elembert_toxic_sr-atad5_V1_E_32_H_2_L_2.h5\n",
            "228/228 [==============================] - 3s 13ms/step - loss: 0.1009 - auc_14: 0.9920 - val_loss: 0.1474 - val_auc_14: 0.9802\n",
            "Epoch 23/64\n",
            "228/228 [==============================] - 3s 15ms/step - loss: 0.1026 - auc_14: 0.9919 - val_loss: 0.1504 - val_auc_14: 0.9779\n",
            "Epoch 24/64\n",
            "228/228 [==============================] - 3s 12ms/step - loss: 0.0975 - auc_14: 0.9927 - val_loss: 0.1555 - val_auc_14: 0.9803\n",
            "Epoch 25/64\n",
            "228/228 [==============================] - 3s 12ms/step - loss: 0.0968 - auc_14: 0.9928 - val_loss: 0.1428 - val_auc_14: 0.9811\n",
            "Epoch 26/64\n",
            "228/228 [==============================] - 3s 12ms/step - loss: 0.0991 - auc_14: 0.9920 - val_loss: 0.1505 - val_auc_14: 0.9778\n",
            "Epoch 27/64\n",
            " 70/228 [========>.....................] - ETA: 1s - loss: 0.1006 - auc_14: 0.9914\n",
            "Epoch 27: saving model to /content/elementsem/models/elembert_toxic_sr-atad5_V1_E_32_H_2_L_2.h5\n",
            "228/228 [==============================] - 4s 16ms/step - loss: 0.0923 - auc_14: 0.9931 - val_loss: 0.1540 - val_auc_14: 0.9778\n",
            "Epoch 28/64\n",
            "228/228 [==============================] - 3s 13ms/step - loss: 0.0920 - auc_14: 0.9935 - val_loss: 0.1419 - val_auc_14: 0.9805\n",
            "Epoch 29/64\n",
            "228/228 [==============================] - 3s 13ms/step - loss: 0.0928 - auc_14: 0.9929 - val_loss: 0.1549 - val_auc_14: 0.9806\n",
            "Epoch 30/64\n",
            "228/228 [==============================] - 3s 12ms/step - loss: 0.0879 - auc_14: 0.9939 - val_loss: 0.1767 - val_auc_14: 0.9734\n",
            "Epoch 31/64\n",
            "158/228 [===================>..........] - ETA: 0s - loss: 0.0855 - auc_14: 0.9946\n",
            "Epoch 31: saving model to /content/elementsem/models/elembert_toxic_sr-atad5_V1_E_32_H_2_L_2.h5\n",
            "228/228 [==============================] - 4s 16ms/step - loss: 0.0874 - auc_14: 0.9943 - val_loss: 0.1681 - val_auc_14: 0.9757\n",
            "Epoch 32/64\n",
            "228/228 [==============================] - 4s 16ms/step - loss: 0.0835 - auc_14: 0.9941 - val_loss: 0.1636 - val_auc_14: 0.9750\n",
            "Epoch 33/64\n",
            "228/228 [==============================] - 3s 14ms/step - loss: 0.0844 - auc_14: 0.9943 - val_loss: 0.1586 - val_auc_14: 0.9763\n",
            "Epoch 34/64\n",
            "228/228 [==============================] - 3s 13ms/step - loss: 0.0838 - auc_14: 0.9943 - val_loss: 0.1593 - val_auc_14: 0.9753\n",
            "Epoch 35/64\n",
            "228/228 [==============================] - 3s 15ms/step - loss: 0.0836 - auc_14: 0.9940 - val_loss: 0.1560 - val_auc_14: 0.9767\n",
            "Epoch 36/64\n",
            " 15/228 [>.............................] - ETA: 2s - loss: 0.1113 - auc_14: 0.9924\n",
            "Epoch 36: saving model to /content/elementsem/models/elembert_toxic_sr-atad5_V1_E_32_H_2_L_2.h5\n",
            " 25/228 [==>...........................] - ETA: 3s - loss: 0.0970 - auc_14: 0.9938"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save results"
      ],
      "metadata": {
        "id": "XXCpaPQlNpRc"
      },
      "id": "XXCpaPQlNpRc"
    },
    {
      "cell_type": "code",
      "source": [
        "extractorEmb = Model(inputs=model.inputs,outputs=model.get_layer(name=\"clsTokenEmb\").output)\n",
        "\n",
        "preds = model.predict(x3,batch_size = config.BATCH_SIZE)\n",
        "\n",
        "dbresults={}\n",
        "dbresults['pred_emb'] = extractorEmb.predict(x3,batch_size = config.BATCH_SIZE)\n",
        "dbresults['pred_cls'] = preds\n",
        "dbresults['y_cls'] = labels\n",
        "dbresults['formula'] = df['formula']\n",
        "dbresults['ids'] = df['ids']\n",
        "dbresults['types'] = types\n",
        "dbresults['trainidx'] = trainidx\n",
        "dbresults['testidx'] = validx\n",
        "dbresults['validx'] = validx\n",
        "\n",
        "with open(mname+'_results.pkl', 'wb') as f:\n",
        "    pickle.dump(dbresults, f)"
      ],
      "metadata": {
        "id": "UX22_sNiNoyU"
      },
      "id": "UX22_sNiNoyU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Postprocessing"
      ],
      "metadata": {
        "id": "UzAbw5kcQPmb"
      },
      "id": "UzAbw5kcQPmb"
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import cm\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "tsne = TSNE(n_components=2, verbose=0, random_state=123)\n",
        "z = tsne.fit_transform(dbresults['pred_emb'])"
      ],
      "metadata": {
        "id": "y_B7Z0AaQR83"
      },
      "id": "y_B7Z0AaQR83",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfr = pd.DataFrame()\n",
        "dfr[\"y\"] = np.asarray(dbresults['y_cls'].argmax(axis=-1)).astype('bool')\n",
        "dfr[\"yp\"] = np.asarray(dbresults['pred_cls'].argmax(axis=-1)).astype('bool')\n",
        "dfr[\"tSNE1\"] = z[:,0]\n",
        "dfr[\"tSNE2\"] = z[:,1]"
      ],
      "metadata": {
        "id": "y2nwnEEBa11h"
      },
      "id": "y2nwnEEBa11h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams.update({'font.size': 16})\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4.8))\n",
        "y_pclasses = dbresults['pred_cls'][dbresults['testidx']].argmax(axis=-1)\n",
        "y_classes = dbresults['y_cls'][dbresults['testidx']].argmax(axis=-1)\n",
        "m = tf.keras.metrics.AUC()\n",
        "m.update_state(dbresults['y_cls'][dbresults['testidx']], dbresults['pred_cls'][dbresults['testidx']])\n",
        "print(mname,'binary tf-acc:',tf.keras.metrics.binary_accuracy(y_classes, y_pclasses, threshold=0.5).numpy(),'AUC:',m.result().numpy())\n",
        "confusion_matrix = metrics.confusion_matrix(y_classes, y_pclasses)\n",
        "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix,\n",
        "                                            display_labels=['False','True'])\n",
        "cm_display.plot(ax=axes[0],cmap=plt.cm.Blues)\n",
        "\n",
        "sns.scatterplot(ax=axes[1],x=\"tSNE1\", y=\"tSNE2\", hue=dfr.y.tolist(),data=dfr)#.set(title=title+\" data T-SNE projection\")\n",
        "axes[1].set_xlabel('$tSNE_1$')\n",
        "axes[1].set_ylabel('$tSNE_2$',labelpad=1)\n",
        "axes[1].set_title('Reference')\n",
        "sns.scatterplot(ax=axes[2],x=\"tSNE1\", y=\"tSNE2\", hue=dfr.yp.tolist(),data=dfr)#.set(title=title+\" data T-SNE projection\")\n",
        "axes[2].set_title('Predicted')\n",
        "axes[2].set_xlabel('$tSNE_1$')\n",
        "axes[2].set_ylabel('$tSNE_2$',labelpad=1)\n",
        "axes[2].legend('',frameon=False)\n",
        "fig.tight_layout()\n",
        "plt.show()\n",
        "plt.savefig(mname+'_tsne.jpg',format='jpg',dpi=800,bbox_inches = \"tight\",pil_kwargs={\"compression\": \"tiff_lzw\"})"
      ],
      "metadata": {
        "id": "UJeoJjKSQyV_"
      },
      "id": "UJeoJjKSQyV_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.max([len(i) for i in types])"
      ],
      "metadata": {
        "id": "mgph5yf63b22"
      },
      "id": "mgph5yf63b22",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "/content/elementsem/models/elembert_toxic_sr-p53_V0_E_32_H_2_L_2 binary tf-acc: 0.96871376 AUC: 0.98945105\n",
        "/content/elementsem/models/elembert_toxic_sr-p53_V1_E_32_H_2_L_2 binary tf-acc: 0.9571263  AUC: 0.9820951\n",
        "/content/elementsem/models/elembert_toxic_sr-mmp_V0_E_32_H_2_L_2 binary tf-acc: 0.8920765 AUC: 0.9487883\n",
        "/content/elementsem/models/elembert_toxic_sr-mmp_V1_E_32_H_2_L_2 binary tf-acc: 0.90163934 AUC: 0.94474494\n",
        "/content/elementsem/models/elembert_toxic_sr-hse_V0_E_32_H_2_L_2 binary tf-acc: 0.94969326 AUC: 0.95752335\n",
        "/content/elementsem/models/elembert_toxic_sr-hse_V1_E_32_H_2_L_2 binary tf-acc: 0.9190184 AUC: 0.9508389"
      ],
      "metadata": {
        "id": "8MMeqoheGGPg"
      },
      "id": "8MMeqoheGGPg"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LC4rkkiiGHIt"
      },
      "id": "LC4rkkiiGHIt",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}